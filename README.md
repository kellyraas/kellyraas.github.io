### kellyraas.github.io

# First Data Science Projects

This is a repository of projects and assignments I worked on during my Data Science Master's Degree in 2019. Click on the headlines to see the full report and code.

## [Data_Mining](https://kellyraas.github.io/Projects/Data_Mining/Data_Mining.html)
*June 2019* </br>
- Part 1: Association Rule Mining
  - Finding Frequent Itemsets
  - Apriori Algorithm
- Part 2: Anomaly Detection
  - Mahalanobi distance (distance-based)
  - LOF Algorithm (density-based)
  - DBSCAN (clusetering-based)
  - Expectation Maximisation (clistering-based)
- **Keywords**(R, Data Mining, Apriori, Anomaly Detection)


## [California Housing Prices](https://kellyraas.github.io/Projects/California_Housing_Prices/California_Housing_Prices.html)
*June 2019* </br>
- Data: Housing Data of California 1990 Census (Source: [Kaggle](https://www.kaggle.com/camnugent/california-housing-prices))
- Objective: Predicting the average housing prices
- Regression with Neural Networks
- **Keywords**(R, Regression, Neural Networks, Cross-Validation)


## [Classification of Bank Customers](https://kellyraas.github.io/Projects/Classification_Bank/Bank_Customers_Classificacion.html)
*June 2019* </br>
- Data: 42k+ Observations on customers affected by a direct marketing campaign
- Objective: predicting whether bank clients will subscribe a term deposit  
- Binary Classification
- Model comparison
- **Keywords**(R, Classification, SVM, ANN)


## [Black Friday: EDA, Spending Prediction and Recommendation System](https://kellyraas.github.io/Projects/Black_Friday/Black_Friday.html)
*January 2019* </br>
*In collaboration with [Hendrik Mischo](https://github.com/hendrik-mischo)*
- Data: 550k+ Observations about Black Friday Sales (Source: [Kaggle](https://www.kaggle.com/mehdidag/black-friday/home))
- Explorative Data Analysis
- Testing for Pareto Principle (80/20 Rule)
- Predict customer spending using Regression Model and Random Forest
- Building a Recommendation System
- **Keywords**(R, Tidyverse, ggplot, Linear Regression, Random Forest, Recommenderlab)


## [Outcome Class Prediction for Austin Shelter Dogs](https://kellyraas.github.io/Projects/Austin_Animal_Shelter/Austin_Animal_Shelter.html)
*January 2019*
- Data: 79k+ Observations on animals entering the Austin Animal Center. (Source: [Kaggle](https://www.kaggle.com/aaronschlegel/austin-animal-center-shelter-intakes-and-outcomes#aac_outcomes.csv))
- Data wrangling
- Implementing H2O.ai's machine learning platform
- Class prediction using Random Forest Classification and Gradient Boosting Model
- Parameter tuning with grid search </br>
- **Keywords**(R, H2O, Classification, Random Forest, Gradient Boosting, Machine Learning)

## [Monty Hall Paradox Simulation](kellyraas.github.io/Projects/Monty_Hall_Simulation/Monty_Hall_Simulation.html)
*January 2019* </br>
After watching the movie "21" I found myself in a discussion about the Monty Hall Paradox so I decided to run a quick simulation in R code.
